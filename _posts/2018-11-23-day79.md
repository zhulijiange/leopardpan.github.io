---
layout: post
title: 'day79笔记-解析模块, 存入数据库'
description: 爬虫
tag: 博客
---     
###  解析模块
     1. 数据的分类
       1. 结构化数据
         特点: 有固定的格式, 如: html, xml
       2. 非结构化数据
         示例: 图片, 音频, 视频, 这类数据以二进制方式存储
    2. 正则表达式 re
      1. 使用流程
        1. 创建编译对象: p = re.compile('正则表达式')
        2. 对字符串进行匹配: r = p.match('字符串')
        3. 获取匹配结果: r.group()
      2. 常用方法
        1. match(html): 字符串开头的第一个, 返回对象
        2. search(html): 从开头往后找, 匹配第一个, 返回对象
        3. findall(html): 所有全部都去匹配, 返回列表
      3. 表达式
        .: 匹配任意字符(不包括\n)
        \d: 数字
        \s: 空白字符
        \S: 非空白
        \w: 字母, 数字, _
        [...]: 包含[]内容: A[BCD]E --> ABE ACE ADE

        *: 0次或多次
        ?: 0次或1次
        +: 1次或多次
        {m}: m次
        {m,n}: m-n次, AB{1,3}C --> ABC ABBC ABBBC
      4. 贪婪匹配和非贪婪匹配
        贪婪匹配(.*): 在整个表达式匹配成功的前提下, 尽可能多的匹配*
        非贪婪匹配(.*?): 在整个表达式匹配成功的前提下, 尽可能少的匹配*
      5. findall()的分组
      6. 练习
        <div class='animal'>
          <p class='name'>
            <a title='tiger'></a>
          </p>
          <p class="contents">
            Two tigers two tigers run fast
          </p>
        </div>
        <div class='animal'>
          <p class='name'>
            <a title='rabbit'></a>
          </p>
          <p class="contents">
            Small white rabbit white and white
          </p>
        </div>
        第一步:
        [("tiger", "Two tigers two tigers run fast"), (...)]
        第二步:
        动物名称: tiger
        动物描述: Two tigers two tigers run fast
        ...

    3. 内涵段子脑筋急转弯抓取
      网址:https://www.neihan8.com/njjzw//
      1. 步骤
        1. 找URL规律
          第1页: https://www.neihan8.com/njjzw/index.html
          第2页: https://www.neihan8.com/njjzw/index_2.html
        2. 用正则匹配出题目和答案
        3. 写代码
          1. 发送请求
          2. 用正则解析
          3. 保存
    4. 猫眼电影top100榜单, 存到csv文件里
      网址: 猫眼电影 - 榜单 - top100
      目标: 抓取电影名, 主演, 上映时间
      1. 知识点
        1. csv模块的使用流程
          1. 打开csv文件
            with open("测试.csv", 'a', newline='') as f:
          2. 初始化写入对象
            writer = csv.writer(f)
          3. 写入数据
            writer.writerow([列表])
      2. 准备工作
        1. 找url规律
          第一页: http://maoyan.com/board/4?offset=0
          第二页: http://maoyan.com/board/4?offset=10
          第三页: http://maoyan.com/board/4?offset=20
        2. 写正则表达式
          <div class="movie-item-info">.*?title="(.*?)".*?class="star">(.*?)</p>.*?class="releasetime">(.*?)</p>
        3. 写代码
        4. 存csv文件

### 数据的持久化存储
    1. 存入MongoDB数据库(pymongo模块回顾)
      # 连接对象
      conn = pymongo.MongoClient("client", 27017)
      # 数据对象
      db = conn.库名
      # 集合对象
      myset = db.集合名
      # 插入数据
      myset.insert(字典)

      >>>db.集合名.find().pretty()
      >>>db.集合名.count()
    2. 存入MySQL数据库(pymysql模块回顾)
    3. requests模块
      1. 安装
        Anaconda Prompt: conda install requests
        Windows cmd: python -m pip install requests
        ## python -m 是以管理员身份执行pip安装命令
        Ubuntu: sudo pip3 install requests
      2. 常用方法
        1. get(url, headers=headers)
          发起请求, 并获取响应对象
        2. 响应对象res的属性
          1. res.text: 字符串
          2. res.content: 字节流
          3. res.encoding: 指定字符编码 (ISO-8859-1)
            ## res.encoding = 'utf-8'
          4. res.status_code: 响应码
          5. res.url: 实际数据的url
        3. get()使用场景
          1. 没有查询参数
            res = requests.get(url, headers=headers)
          2. 有查询参数(params)
            res = requests.get(url, params=params, headers=headers)
